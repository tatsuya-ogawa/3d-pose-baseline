{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "KxYHxu7h6zaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b777d9d7-2d72-4535-8c20-36f44f80e27a"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GMUZS1Vp68BH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "601eb273-2d5d-450e-8cd2-6f977826dbb8"
      },
      "cell_type": "code",
      "source": [
        "!ls ./gdrive/'My Drive'/\"Colab Notebooks\"/cifar10"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t_train.npy  x_test.npy  x_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dKwu_IDr_VOu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "def load_cifar10():\n",
        "    data_dir = './gdrive/My Drive/Colab Notebooks/cifar10/'\n",
        "    # 学習データ\n",
        "    x_train = np.load(os.path.join(data_dir,'x_train.npy'))\n",
        "    t_train = np.load(os.path.join(data_dir,'t_train.npy'))\n",
        "\n",
        "    # テストデータ\n",
        "    x_test = np.load(os.path.join(data_dir,'x_test.npy'))\n",
        "    \n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    x_test = x_test.astype('float32') / 255\n",
        "    \n",
        "    t_train = np.eye(10)[t_train.astype('int32').flatten()]\n",
        "    \n",
        "    return (x_train, x_test, t_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BV5niZbw_nLR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%%writefile /root/userspace/submission_code.py\n",
        "def main():\n",
        "  import tensorflow as tf\n",
        "  from sklearn.utils import shuffle\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.metrics import accuracy_score\n",
        "\n",
        "  rng = np.random.RandomState(1234)\n",
        "  random_state = 42\n",
        "\n",
        "  def tf_log(x):\n",
        "      # WRITE ME\n",
        "      return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
        "  ### ネットワーク ###\n",
        "  tf.reset_default_graph()\n",
        "  is_training = tf.placeholder(tf.bool, shape=())\n",
        "\n",
        "  # WRITE ME\n",
        "  ###################################################################################\n",
        "\n",
        "  x = tf.placeholder(shape=[None, 32, 32, 3], dtype=tf.float32)\n",
        "  t = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "  ### ネットワーク ###\n",
        "  h = tf.layers.Conv2D(filters=32, kernel_size= [3, 3])(x) # 32x32x3 -> 30x30x32 # conv2dの初期設定: strides=(1, 1), padding='valid' \n",
        "  h = tf.layers.BatchNormalization()(h, training=is_training)\n",
        "  h = tf.nn.relu(h)\n",
        "  h = tf.layers.MaxPooling2D(pool_size=[2, 2], strides=2)(h) # 30x30x32 -> 15x15x32\n",
        "\n",
        "  h = tf.layers.Conv2D(filters=64, kernel_size= [3, 3])(h) # 15x15x32 -> 13x13x64\n",
        "  h = tf.layers.BatchNormalization()(h, training=is_training)\n",
        "  h = tf.nn.relu(h)\n",
        "  h = tf.layers.MaxPooling2D(pool_size=[2, 2], strides=2)(h) # 13x13x64 -> 6x6x64\n",
        "\n",
        "  h = tf.layers.Conv2D(filters=128, kernel_size= [3, 3])(h) # 6x6x64 -> 4x4x128\n",
        "  h = tf.layers.BatchNormalization()(h, training=is_training)\n",
        "  h = tf.nn.relu(h)\n",
        "  h = tf.layers.MaxPooling2D(pool_size=[2, 2], strides=2)(h) # 4x4x128 -> 2x2x128\n",
        "\n",
        "  h = tf.layers.Flatten()(h)\n",
        "  h = tf.layers.Dense(units=256, activation=tf.nn.relu)(h)\n",
        "  y = tf.layers.Dense(units=10, activation=tf.nn.softmax)(h) # WRITE ME\n",
        "\n",
        "  cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1))\n",
        "  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "\n",
        "  with tf.control_dependencies(update_ops):\n",
        "      optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
        "\n",
        "  ###################################################################################\n",
        "\n",
        "\n",
        "  ### 前処理 ###\n",
        "  def gcn(x):\n",
        "      # WRITE ME\n",
        "      mean = np.mean(x, axis=(1, 2, 3), keepdims=True)\n",
        "      std = np.std(x, axis=(1, 2, 3), keepdims=True)\n",
        "      return (x - mean)/std\n",
        "\n",
        "  class ZCAWhitening:\n",
        "      # WRITE ME\n",
        "      def __init__(self, epsilon=1e-4):\n",
        "          self.epsilon = epsilon\n",
        "          self.mean = None\n",
        "          self.ZCA_matrix = None\n",
        "\n",
        "      def fit(self, x):\n",
        "          x = x.reshape(x.shape[0], -1)\n",
        "          self.mean = np.mean(x, axis=0)\n",
        "          x -= self.mean\n",
        "          cov_matrix = np.dot(x.T, x) / x.shape[0]\n",
        "          A, d, _ = np.linalg.svd(cov_matrix)\n",
        "          self.ZCA_matrix = np.dot(np.dot(A, np.diag(1. / np.sqrt(d + self.epsilon))), A.T)\n",
        "\n",
        "      def transform(self, x):\n",
        "          shape = x.shape\n",
        "          x = x.reshape(x.shape[0], -1)\n",
        "          x -= self.mean\n",
        "          x = np.dot(x, self.ZCA_matrix.T)\n",
        "          return x.reshape(shape)\n",
        "\n",
        "  x_train, x_test, t_train = load_cifar10()\n",
        "  x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
        "  zca = ZCAWhitening()\n",
        "  zca.fit(x_train)\n",
        "  x_train_zca = zca.transform(gcn(x_train))\n",
        "  t_train_zca = t_train[:]\n",
        "  x_valid_zca = zca.transform(gcn(x_valid))\n",
        "  t_valid_zca = t_valid[:]\n",
        "  x_test_zca = zca.transform(gcn(x_test))\n",
        "\n",
        "  ### 学習 ###\n",
        "  n_epochs = 10\n",
        "  batch_size = 100\n",
        "  n_batches = x_train.shape[0]//batch_size\n",
        "\n",
        "  sess = tf.Session()\n",
        "  init = tf.global_variables_initializer()\n",
        "  sess.run(init)\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      # WRITE ME\n",
        "      x_train_zca, t_train_zca = shuffle(x_train_zca, t_train_zca, random_state=random_state)\n",
        "      for batch in range(n_batches):\n",
        "          start = batch * batch_size\n",
        "          end = start + batch_size\n",
        "          sess.run(optimizer, feed_dict={x: x_train_zca[start:end], t: t_train_zca[start:end], is_training: True})\n",
        "      y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid_zca, t: t_valid_zca, is_training: False})\n",
        "      print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
        "          epoch,\n",
        "          cost_valid,\n",
        "          accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "      ))\n",
        "  sess.close()\n",
        "\n",
        "  y_pred = None # WRITE ME\n",
        "  submission = pd.Series(y_pred, name='label')\n",
        "  #submission.to_csv('/root/userspace/submission_pred.csv', header=True, index_label='id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SIvYR-8tBnSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2111
        },
        "outputId": "2bf8f12e-92a2-4531-bbef-7ebf1056bc71"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "import os\n",
        "def build_model(input_shape, num_classes):\n",
        "#   source = tf.keras.Input(name=\"seed\", shape=input_shape, batch_size=batch_size)\n",
        "  source = tf.keras.Input(name=\"seed\", shape=input_shape)\n",
        "  x = tf.keras.layers.Convolution2D(192,(5,5),strides=(1,1),padding='same',activation='relu')(source)\n",
        "  x = tf.keras.layers.Convolution2D(160,(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
        "  x = tf.keras.layers.Convolution2D(96,(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.MaxPool2D((3,3),strides=(2,2),padding='same')(x)          \n",
        "  x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "  x = tf.keras.layers.Convolution2D(192,(5,5),strides=(1,1),padding='same',activation='relu')(x)\n",
        "  x = tf.keras.layers.Convolution2D(192,(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
        "  x = tf.keras.layers.Convolution2D(192,(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.AvgPool2D((3,3),strides=(2,2),padding='same')(x)          \n",
        "  x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "  x = tf.keras.layers.Convolution2D(192,(3,3),strides=(1,1),padding='same',activation='relu')(x)\n",
        "  x = tf.keras.layers.Convolution2D(192,(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
        "  x = tf.keras.layers.Convolution2D(num_classes,(1,1),1,padding='same',activation='relu')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.AvgPool2D((8,8),1,padding='valid')(x)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  model = tf.keras.Model(inputs=[source], outputs=[x])\n",
        "  return model\n",
        "\n",
        "def get_data_generator(batch_size):\n",
        "  rng = np.random.RandomState(1234)\n",
        "  random_state = 42\n",
        "  \n",
        "  x_train, x_test, t_train = load_cifar10()\n",
        "  x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
        "  \n",
        "  datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "  \n",
        "  # compute quantities required for featurewise normalization\n",
        "  # (std, mean, and principal components if ZCA whitening is applied)\n",
        "  datagen.fit(x_train)\n",
        "\n",
        "def to_tpu(model):\n",
        "  tpu_grpc_url = \"grpc://\"+os.environ[\"COLAB_TPU_ADDR\"]\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "  strategy = tf.contrib.tpu.TPUDistributionStrategy(tpu_cluster_resolver)\n",
        "  model = tf.contrib.tpu.keras_to_tpu_model(model, strategy=strategy)\n",
        "  return model\n",
        "\n",
        "def save_history(history):\n",
        "  history_dir = './gdrive/My Drive/Colab Notebooks/history'\n",
        "  with open(os.path.join(history_dir,'cifar10.dat'), \"wb\") as fp:\n",
        "    pickle.dump(history, fp)\n",
        "  \n",
        "def train():\n",
        "  rng = np.random.RandomState(1234)\n",
        "  random_state = 42\n",
        "  x_train, x_test, t_train = load_cifar10()\n",
        "  x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
        "    \n",
        "  \n",
        "  batch_size=2048#256\n",
        "  learning_rate=0.01\n",
        "  nb_epoch = 10\n",
        "  model = build_model((32,32,3),10)\n",
        "  print(model.summary())\n",
        "  model.compile(optimizer=tf.keras.optimizers .Adam(lr=learning_rate), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  model = to_tpu(model)\n",
        "  \n",
        "  \n",
        "  datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=False,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zca_whitening=False\n",
        "  )  \n",
        "  datagen.fit(x_train)  \n",
        "  history = model.fit(x_train, t_train, batch_size=batch_size, epochs=nb_epoch, validation_data=(x_valid, t_valid)).history\n",
        "  model.fit_generator(datagen.flow(x_train, t_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=len(x_train) / batch_size, epochs=nb_epoch,\n",
        "                     validation_data=(x_valid, t_valid)\n",
        "                     )\n",
        "  for e in range(epochs):\n",
        "    print('Epoch', e)\n",
        "    batches = 0\n",
        "    for x_batch, t_batch in datagen.flow(x_train, t_train, batch_size=batch_size):\n",
        "        history=model.fit(x_batch, t_batch).history\n",
        "        batches += 1\n",
        "        if batches >= len(x_train) / batch_size:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "            break\n",
        "    save_history(history)\n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "seed (InputLayer)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 32, 32, 192)       14592     \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 32, 32, 160)       30880     \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           (None, 32, 32, 96)        15456     \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 16, 16, 192)       460992    \n",
            "_________________________________________________________________\n",
            "conv2d_85 (Conv2D)           (None, 16, 16, 192)       37056     \n",
            "_________________________________________________________________\n",
            "conv2d_86 (Conv2D)           (None, 16, 16, 192)       37056     \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_18 (Averag (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_87 (Conv2D)           (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "conv2d_88 (Conv2D)           (None, 8, 8, 192)         37056     \n",
            "_________________________________________________________________\n",
            "conv2d_89 (Conv2D)           (None, 8, 8, 10)          1930      \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 8, 8, 10)          40        \n",
            "_________________________________________________________________\n",
            "average_pooling2d_19 (Averag (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 968,178\n",
            "Trainable params: 967,582\n",
            "Non-trainable params: 596\n",
            "_________________________________________________________________\n",
            "None\n",
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.42.75.26:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 1349449978205875094)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12447798957708463109)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 5185414088682322597)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10128633650370942063)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 11429778733128505676)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 10660092307484647282)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11666147448000183089)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 5879771179232130210)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 5217839021411852125)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 16112914390858807585)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 8983394254537467818)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 14962562888485202563)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.009999999776482582, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.009999999776482582, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(256,), dtype=tf.int32, name='core_id_40'), TensorSpec(shape=(256, 32, 32, 3), dtype=tf.float32, name='seed_120'), TensorSpec(shape=(256, 10), dtype=tf.float32, name='flatten_9_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.009999999776482582, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for seed\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7fc3c446af60> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 15.754034042358398 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.009999999776482582 {0.01}\n",
            "INFO:tensorflow:CPU -> TPU beta_1: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU beta_2: 0.9990000128746033 {0.999}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "40960/45000 [==========================>...] - ETA: 5s - loss: 2.9224 - acc: 0.1162INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(249,), dtype=tf.int32, name='core_id_40'), TensorSpec(shape=(249, 32, 32, 3), dtype=tf.float32, name='seed_120'), TensorSpec(shape=(249, 10), dtype=tf.float32, name='flatten_9_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for seed\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7fc3c446af60> [<tf.Variable 'tpu_140478792625400/Adam/iterations:0' shape=() dtype=int64>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2dd47b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2dd4c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2d7c320>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2d98f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2d3fa58>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2cb1d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2c7eda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2c27eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2bf02b0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2b64dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2b32e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2afdf98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2acaf28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2a94d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c29e3fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2a0df98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c29d5c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2949dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2917d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2861ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2830d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c27fe898>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c27ccfd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2770cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c273ce10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c26ad588>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c267de10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c264a9e8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2614f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2588d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c252e4e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c24fae48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c249ecf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c243bef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c23e40f0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c23d0e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c237ad30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c22edfd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c22bbf60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2260e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c222c1d0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c21a0cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c216bc88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2136cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2106ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c20d3d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c201eeb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c2044f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c200fb38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1fdcac8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1f2c3c8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1efab38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1ec59e8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1e93b38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1de2be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1dd8f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1d23da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1ceeef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1cbaf98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1c88d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1c56e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1ba2630>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1b719e8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1b3db38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1b0c9e8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1ad7b38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1a28be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c199ef60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1965da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c1931ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c18fff98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fc3c18cbd30>]\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 15.818484783172607 secs\n",
            "43008/45000 [===========================>..] - ETA: 3s - loss: 2.8997 - acc: 0.1163INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(256,), dtype=tf.int32, name='core_id_50'), TensorSpec(shape=(256, 32, 32, 3), dtype=tf.float32, name='seed_120'), TensorSpec(shape=(256, 10), dtype=tf.float32, name='flatten_9_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.009999999776482582, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for seed\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7fc3bdb39fd0> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 12.753096342086792 secs\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(113,), dtype=tf.int32, name='core_id_50'), TensorSpec(shape=(113, 32, 32, 3), dtype=tf.float32, name='seed_120'), TensorSpec(shape=(113, 10), dtype=tf.float32, name='flatten_9_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for seed\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7fc3bdb39fd0> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 7.236290454864502 secs\n",
            "45000/45000 [==============================] - 112s 2ms/step - loss: 2.8791 - acc: 0.1165 - val_loss: 2.3064 - val_acc: 0.0922\n",
            "Epoch 2/10\n",
            "45000/45000 [==============================] - 5s 104us/step - loss: 2.3917 - acc: 0.1087 - val_loss: 2.3064 - val_acc: 0.1030\n",
            "Epoch 3/10\n",
            "45000/45000 [==============================] - 5s 105us/step - loss: 2.3906 - acc: 0.1027 - val_loss: 2.3174 - val_acc: 0.1006\n",
            "Epoch 4/10\n",
            "45000/45000 [==============================] - 5s 107us/step - loss: 2.3814 - acc: 0.1054 - val_loss: 2.3152 - val_acc: 0.1006\n",
            "Epoch 5/10\n",
            "45000/45000 [==============================] - 5s 103us/step - loss: 2.3921 - acc: 0.0949 - val_loss: 2.3244 - val_acc: 0.1006\n",
            "Epoch 6/10\n",
            "45000/45000 [==============================] - 5s 108us/step - loss: 2.3591 - acc: 0.0856 - val_loss: 2.3252 - val_acc: 0.1006\n",
            "Epoch 7/10\n",
            "45000/45000 [==============================] - 5s 111us/step - loss: 2.3603 - acc: 0.0899 - val_loss: 2.3396 - val_acc: 0.1006\n",
            "Epoch 8/10\n",
            "45000/45000 [==============================] - 5s 104us/step - loss: 2.3543 - acc: 0.0942 - val_loss: 2.5437 - val_acc: 0.0930\n",
            "Epoch 9/10\n",
            "45000/45000 [==============================] - 5s 107us/step - loss: 2.4156 - acc: 0.0964 - val_loss: 2.3415 - val_acc: 0.1006\n",
            "Epoch 10/10\n",
            "45000/45000 [==============================] - 5s 106us/step - loss: 2.6761 - acc: 0.1024 - val_loss: 2.3087 - val_acc: 0.1030\n",
            "Epoch 1/10\n",
            " 6/21 [=======>......................] - ETA: 13s - loss: 2.9343 - acc: 0.0959"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mLEiAbC7M8S1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bj90C2BENd2F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}